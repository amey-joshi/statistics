---
title: "Preliminary examination"
author: "Amey Joshi"
date: "29/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(MASS)

training.data <- read.csv("train.csv")
```

```{r}
data_availability <- function(column.name, show.grp.size = TRUE) {
    num.na <- sum(is.na(training.data$column.name))
    cat(
        paste(
            "The proportion of values for which",
            column.name,
            "is NA is",
            num.na / nrow(training.data),
            "\n"
        )
    )
    
    if (show.grp.size) {
        grp.size <- tapply(training.data$SalePrice,
                           training.data[[column.name]],
                           length)
        cat(paste("Group size of", column.name, "are:\n"))
        print(grp.size)
        cat("\n")
    }
    
    rm(num.na)
}

check_group_means <- function(column.name) {
    grp.means <- tapply(training.data$SalePrice,
                        training.data[[column.name]],
                        mean)
    cat(paste("Group means of", column.name, "are:\n"))
    cat(grp.means)
    cat("\n")
    
    anova.res <-
        oneway.test(training.data$SalePrice ~ training.data[[column.name]])
    print(anova.res)
    rm(anova.res)
    
    boxplot(training.data$SalePrice ~ training.data[[column.name]],
            xlab = column.name,
            ylab = "Sale Price")
}
```

## Observations
The observations listed in this section are substantiated in the rest of the 
analysis.

1.  Sale price for different sales condition is different. The categories 
    'Abnorml' and 'Family' are statistically similar.
2.  It might be useful to collapse sale type into 'Normal', 'New' and 'Others'.
    Sale type and sale condition seem to be closely related to each other. We can
    think of retaining only one of them.
3.  We need both Zoning classification and the dwelling type.
4.  Neither lot frontage nor lot area are strongly correlated with sale price.
5.  Street and Alley may not be a good predictor of sale price.
6.  Lot shape may be a predictor of sale price.
7.  Land contour too may be a predictor of sale price.
8.  Utilities cannot be used used to predict sale price.
9.  Lot configuration may be a good predictor but it may be helpful to collapse
    a few levels.
10. Land slope is not a candidate predictor of sale price.  
11. Neighborhood is a predictor of sale price.
12. Proximity to various conditions (Condition1) may be good predictors of sale 
    price. However, Condition2 might not be very helpful. The $9$ levels of 
    Condition1 can be coalesced into three.
13. BldgType may be a predictor of sale price. Its $5$ levels can be coalesced
    into $2$.
14. HouseStyle may be a predictor of sale price.
15. Overall quality and condition are strong predictors of sale price.
16. YearBuilt and YearRemodAdd are useful to predict sale price. However, we
    must transform them to intervals of age and 'years since last remodeling'
    before we can use them.
17. Roof style may be used as a predictor. Roof material can be used only if
    we collapse its eight levels into two.
    
## Condition of sale
We first find the distribution of 'condition of sale'
```{r}
with(training.data,
     tapply(SalePrice, SaleCondition, function(x) {
       round(length(x)/nrow(training.data), 4)
     }))
```

A significant percentage of sales were normal. Is there a statistically
significant difference in their sale price? We first view the data
```{r}
with(training.data, boxplot(SalePrice ~ SaleCondition))
```

The data shows a large number of outliers even in the 'normal' case. Further,
all outliers are at the higher end of the sale price. Visually, it is hard to
tell if the sale price depends on the sale condition. We run an ANOVA to test it.

```{r}
oneway.test(SalePrice ~ SaleCondition, training.data)
```

The null hypothesis of the one way test is that all the means are equal. The 
test concludes that they are not all equal. Are some of them equal? We first get
the means.
```{r}
with(training.data,
     tapply(SalePrice, SaleCondition, mean))
```

Of these, the 'Abnorml' [sic] and 'Family' means are close by. Let us check if
they are statistically similar.
```{r}
oneway.test(SalePrice ~ SaleCondition, 
            data = training.data[training.data$SaleCondition %in% c("Abnorml", "Family"), ])
```

A $p$-value of $82\%$ suggests that we cannot reject the null hypothesis. The
data suggests that the means are similar. It is possible that 'Family' trades
happen during an abnormal situation and vice versa.

## Sale type
The distribution of sale type is
```{r}
with(training.data,
     tapply(SalePrice, SaleType, function(x) {
       round(length(x)/nrow(training.data), 4)
     }))
```

Is the sale type correlated with the sale condition?
```{r}
with(training.data, 
     table(SaleType, SaleCondition))
```

A large number of WD (Warranty Deed - Conventional) sale type are indeed normal.
The words normal and conventional are synonymous.


The mean sale price across the types is
```{r}
with(training.data,
     tapply(SalePrice, SaleType, mean))
```

It is tempting to conclude that the means are different until one also realizes
that there are only two transactions with sale type 'Cond'.

Does sale type determine sale price? 
```{r}
with(training.data,
     boxplot(SalePrice ~ SaleType))
```

The 'WD' class shows a large number of outliers. But this class also tend to 
have a 'normal' sale condition.

Let us check if the mean sale price is statistically distinct across sale types.
```{r}
oneway.test(SalePrice ~ SaleType, training.data)
```

What was suspected from the box-plot is substantiated by ANOVA. Instead of
looking at all the sale types, what if we club all non-WD together. We create
a new dataset with this change.
```{r}
temp.ds <- training.data[, c("SaleType", "SalePrice")]
temp.ds$SaleType.1 <- ifelse(training.data$SaleType == "WD", "WD", "Non-WD")
oneway.test(SalePrice ~ SaleType.1, data = temp.ds)
```

The 'WD' and 'non-WD' classes are indeed different. Their class means are
```{r}
with(temp.ds,
     tapply(SalePrice, SaleType.1, mean))
```

The distribution of data is
```{r}
with(temp.ds,
     boxplot(SalePrice ~ SaleType.1))
```

Among the 'Non-WD' is 'New' sufficiently different?
```{r}
temp.ds$SaleType.2 <- ifelse(training.data$SaleType == "WD", 
                             "WD",
                             ifelse(training.data$SaleType == "New", 
                                    "New", 
                                    "Others"))
oneway.test(SalePrice ~ SaleType.2, data = temp.ds)
```

It makes sense the separate "New" from the "Non-WD". The new class means are
```{r}
with(temp.ds,
     tapply(SalePrice, SaleType.2, mean))
```

The distribution of data is
```{r}
with(temp.ds,
     boxplot(SalePrice ~ SaleType.2))
```

How different are "Others" from "WD"?
```{r}
oneway.test(SalePrice ~ SaleType.2, data = temp.ds[temp.ds$SaleType.2 %in% c("Others", "WD"), ])
```

They differ but not as significantly as from "New".
```{r}
rm(temp.ds)
```

## Type of dwelling
A distribution of sale price across dwelling types is
```{r}
with(training.data,
     boxplot(SalePrice ~ MSSubClass))
```

Sale price seems to be strongly dependent on the type of the dwelling. The 
differences are visually conspicuous enough to not require a confirmation 
through ANOVA.

We will also look at the number of sales in each category.
```{r}
with(training.data,
     tapply(SalePrice, MSSubClass, function(x) {
       round(length(x)/nrow(training.data), 4)
     }))
```

Unlike the case of sale condition and sale type, dwelling type is not dominated
by one class alone.

## Zoning classification
```{r}
with(training.data,
     boxplot(SalePrice ~ MSZoning))
```


We will also look at the number of sales in each category.
```{r}
with(training.data,
     tapply(SalePrice, MSZoning, function(x) {
       round(length(x)/nrow(training.data), 4)
     }))
```

Most of the sales have happened in RL (Residential Low density) and RM (Residential
Medium density) zones.

How are the dwelling types distributed across zones?
```{r}
tbl.1 <- with(training.data,
              table(MSSubClass, MSZoning))
```

Are the classes 'RL' and 'RM' different? To check that we will first find the
distribution of the number of sales in 'RL' across MSSubClass. We will then run 
a 'goodness of fit' test to check if the 'expected distribution' that mimics that 
of 'RL' is similar to the actual 'RM' data.
```{r}
fisher.test(tbl.1[, c(4, 5)], simulate.p.value = TRUE)
```

The $p$-value indicates that the two distributions are not related. Let us also
check their correlation.
```{r}
cat(paste("Correlation between RL and RH is", 
          round(cor(tbl.1[, 4], tbl.1[, 5]), 4), "\n"))
rm(tbl.1)
```

Thus, we need both Zoning classification and the dwelling type.

## Lot frontage
It is the linear feet of road connecting the property. Let us summarize the
lot frontage data.
```{r}
summary(training.data$LotFrontage)
boxplot(training.data$LotFrontage,
        main = "Lot frontage")
```

Is there a correlation between lot frontage and sale price? Before we find it
we must remove the NAs.
```{r}
cc.lf <- complete.cases(training.data[, c("LotFrontage", "SalePrice")])
X <- training.data[cc.lf, c("LotFrontage", "SalePrice")]
cat(paste("Correlation between lot frontage and sale price is", 
          round(with(X, cor(LotFrontage, SalePrice)), 4),
          "\n"))
```

There is some correlation between the two. Let us visualize the data.
```{r}
with(X, plot(LotFrontage, 
             SalePrice, 
             xlab = "Lot frontage",
             ylab = "Sale price",
             main = "Sale price v Lot frontage"))
rm(cc.lf, X)
```

It is difficult to imagine a linear model predicting sale price using lot
frontage. Before leaving the variable. let us examine the histogram of the lot
frontage.
```{r}
truehist(training.data$LotFrontage, xlab = "Lot frontage")
```

## Lot area
Lot area is the size of the land in square feet. Its summary is
```{r}
summary(training.data$LotArea)
truehist(training.data$LotArea, xlab = "Lot area")
```

The lot area data is highly skewed. There are a very large number of lots with
a size around the median and mean (~ $10,000$ square feet) and a few with very
large size. Let us examine the correlation between lot area and sale price.
```{r}
cat(paste("Correlation between lot area and sale price is", 
          round(with(training.data, cor(LotArea, SalePrice)), 4),
          "\n"))
```

It is interesting to note that two variables do not have a very high correlation.
Perhaps, the land size is a poor predictor of the house price. A plot of sale 
price against the lot area is
```{r}
with(training.data,
     plot(LotArea,
          SalePrice,
          xlab = "Lot area",
          ylab = "Sale price"))
```

## Street
There are only two levels to the variable 'Street', namely 'Grvl' for graveled
and 'Pave' for paved. Let us examine the mean sale price for these factors.
```{r}
with(training.data,
     tapply(SalePrice, Street, mean))
```

On of them is almost $50\%$ higher than the other. Let us confirm that they
are significant using an ANOVA.
```{r}
oneway.test(SalePrice ~ Street, data = training.data)
```

Interestingly, ANOVA does not tell that the two means are statistically 
different. This perhaps indicates that Street might not be a good predictor of
sale price.

We repeat the analysis for the variable 'Alley' which has the same two levels.
```{r}
with(training.data,
     tapply(SalePrice, Alley, mean))
```

The difference is not as sharp as it is in the case of Street. However, if we 
run an ANOVA
```{r}
oneway.test(SalePrice ~ Alley, data = training.data)
```

We realize that Alley matters. The two group means are statistically different.

It is a little baffling that Street and Alley should be so different. Let us 
look a little deeper in the data. We first check the number of NAs.
```{r}
data_availability("Street")
data_availability("Alley")
```

A very large proportion of cases do not have an Alley. Therefore, the statistical
difference in the group means of the levels of Alley may not be useful to predict
the sale price.

## Lot shape
Does regularity of lot shape matter. The group means are
```{r}
with(training.data, 
     tapply(SalePrice,
            LotShape,
            mean))
```

The are distinct. Yet we would like to see the box plot of sale price for each
type of lot shape.
```{r}
with(training.data,
     boxplot(SalePrice ~ LotShape))
```

Are the differences in the means statistically significant?
```{r}
oneway.test(SalePrice ~ LotShape, data = training.data)
```

ANOVA indicates that they are different.

## Land contour
There are four levels of land contour. Their group means are
```{r}
with(training.data, 
     tapply(SalePrice,
            LandContour,
            mean))
```

Their box plot is
```{r}
with(training.data,
     boxplot(SalePrice ~ LandContour))
```

Let us run an ANOVA to compare the group means.
```{r}
oneway.test(SalePrice ~ LandContour, data = training.data)
```

The difference are indeed significant.

## Utilities
Do utilities matter? Do we have enough data?
```{r}
data_availability("Utilities")
```

With just one case available for 'NoSeWa' and all others for 'AllPub' we cannot
use this variable to predict sale price.

## Lot configuration
We first check that we have enough data.
```{r}
data_availability("LotConfig")
```

Although the attribute has data there are only a few cases with FR2 and FR3. We
may want to combine them at a later stage. The group means, ANOVA and box plots 
are
```{r}
check_group_means("LotConfig")
```

The differences in the means are statistically siginificant. Yet, the mean of
FR3 and FR2 are far apart. In fact, 'Corner', 'FR2' and 'Inside' seem be to closer
to each other. Even the box plot seems to suggest the same. We should, therefore,
examine the following possibilities:

1. Combine 'Corner', 'FR2' and 'Inside' in a single category 'CFI'.
2. Keep 'Inside' separate in view of the large number of outliers.

## Land slope
There are three levels of land slope. We first check if there is enough data
for this attribute.
```{r}
data_availability("LandSlope")
```

The group means, ANOVA and box plots are
```{r}
check_group_means("LandSlope")
```

The differences between the group means are not statistically significant. 

## Neighborhood
There are $25$ levels to this attribute. We check the characteristics of the
data.
```{r}
data_availability("Neighborhood")
```

The group means, ANOVA and box plots are
```{r}
check_group_means("Neighborhood")
```

Not surprisingly, neighborhood is a predictor of sale price. 

## Proximity to various conditions
We will study the two conditions together.

```{r}
data_availability("Condition1")
data_availability("Condition2")
```

The data is quite skewed toward normal conditions. Further, almost all data for
'Condition2' is normal making it ineffective for prediction. Let us check if
deviation from normal changes the sale price. We will first analyze with all 
levels of 'Condition1'. The levels of the 'Condition1' (and 'Condition2')
attribute are

- Artery	Adjacent to arterial street
- Feedr	    Adjacent to feeder street	
- Norm	    Normal	       
- RRNn	    Within 200' of North-South Railroad 
- RRAn	    Adjacent to North-South Railroad 
- PosN	    Near positive off-site feature--park, greenbelt, etc. 
- PosA	    Adjacent to postive off-site feature 
- RRNe	    Within 200' of East-West Railroad 
- RRAe	    Adjacent to East-West Railroad

```{r}
check_group_means("Condition1")
```

The conditions which tend to reduce the price are
- Artery
- Feedr
- RRAe

```{r}
oneway.test(SalePrice ~ Condition1, 
            data = training.data, 
            subset = Condition1 %in% c("Artery", "Feedr", "RRAe"))
```

The null hypothesis, that the differences between group means are not 
statistically different, cannot be rejected.

The conditions which probably have no effect are
- Norm (by default)
- RRAn
- RRNe

```{r}
oneway.test(SalePrice ~ Condition1, 
            data = training.data, 
            subset = Condition1 %in% c("Norm", "RRAn", "RRNe"))
```

These three conditions can also be grouped together.

The conditions which tend to increase the price are
- PosA
- PosN
- RRNn

```{r}
oneway.test(SalePrice ~ Condition1, 
            data = training.data, 
            subset = Condition1 %in% c("PosA", "PosN", "RRNn"))
```

These three levels too can be coalesced.

## Building type
There are $5$ levels of this attribute. The characteristic of the data are
```{r}
data_availability("BldgType")
```

The group means, ANOVA and box plots are
```{r}
check_group_means("BldgType")
```

We may have scope to group the attributes. For example, the group means of 
1Fam and TwnHse are quite close. The group means of the other three attributes
too are close enough. It is tempting to check this possiblity right away.
```{r}
oneway.test(SalePrice ~ BldgType, 
            data = training.data, 
            subset = BldgType %in% c("1Fam", "TwnhsE"))
```

The group means can be considered to be equal.

```{r}
oneway.test(SalePrice ~ BldgType, 
            data = training.data, 
            subset = BldgType %in% c("2fmCon", "Duplex", "Twnhs"))
```

One again, the group means can be considered to be equal.

## House style
There are $8$ levelsof house style. The characteristics of the data are
```{r}
data_availability("HouseStyle")
```

The group means, ANOVA and box plots are
```{r}
check_group_means("HouseStyle")
```

## Overall quality and condition
These are numeric attributes. We first check their availablity.
```{r}
data_availability("OverallQual")
data_availability("OverallCond")
```

Is there a correlation between these attributes?
```{r}
with(training.data,
     plot(OverallQual, 
          OverallCond, 
          xlab = "Overall quality", 
          ylab = "Overall condition"))
```

Visually, there is none. Yet. we support our observation by calculating the
correlation coefficient.
```{r}
cat(paste("Correlation between overall quality and overall condition is",
          round(with(training.data, cor(OverallQual, OverallCond)), 4),
          "\n"))
```

Indeed, the two variables are poorly correlated. Let us now check if they are
good predictors of sale price.
```{r}
check_group_means("OverallQual")
```

The overall quality, not surprisingly, is a very strong indicator of sale
price.

```{r}
with(training.data,
     tapply(SalePrice, OverallCond, mean))
with(training.data,
     boxplot(SalePrice ~ OverallCond))
```

We are unable to carry out a full ANOVA because some levels lack data. Let us
check if we can get results by dropping them.
```{r}
oneway.test(SalePrice ~ OverallQual, 
            data = training.data,
            subset = !(OverallQual %in% c(1, 2)))
```

The group means are indeed different.

## Original construction date and remodel date
These are not dates but years. Further, the remodel date is the same as original
construction date if the house has not been remodeled. 
We first check their availablity.
```{r}
data_availability("YearBuilt")
data_availability("YearRemodAdd")
```

There is enough data. However, we must handle this data in a different way. Instead
of considering the raw numbers we should consider the age of the house and the
number of years since last remodeling. We will create a temporary dataframe to
carry out this analysis.
```{r}
age.data <- training.data[, c("YearBuilt", "YearRemodAdd", "YrSold", "SalePrice")]
age.data$Age <- age.data$YrSold - age.data$YearBuilt
age.data$YrSinceLastMod <- age.data$YrSold - age.data$YearRemodAdd
```

Further, the age of the house and the number of years since last remodeling can
be split into intervals. To do so, we need their summary.
```{r}
summary(age.data$Age)
truehist(age.data$Age, xlab = "Age")
```

We will create levels of $20$ years each for the age of the house.
```{r}
summary(age.data$YrSinceLastMod)
truehist(age.data$YrSinceLastMod, xlab = "# years since last remodeling")
```

An interval of $10$ years might suit the attribute 'years since last modeling'.
We now create the interval attributes for each of these variables.
```{r}
age.data$Age.1 <- cut(age.data$Age, 
                      breaks = seq(from = 0, 
                                   to = round(max(age.data$Age)/10)*10, 
                                   by = 20))
age.data$YrSinceLastMod.1 <- 
    cut(age.data$YrSinceLastMod,
        breaks = seq(from = 0, 
                     to = round(max(age.data$YrSinceLastMod)/10)*10, 
                     by = 10))
```

We will now check if the age and years since last modeling are candidate 
predictors of sale price. We first check the group means and box plots.
```{r}
with(age.data,
     tapply(SalePrice, Age.1, mean))
with(age.data,
     boxplot(SalePrice ~ Age.1, xlab = "Age"))
```

The house price decreases with age up to a limit and then rises as houses grow
older. 

```{r}
with(age.data,
     tapply(SalePrice, YrSinceLastMod.1, mean))
with(age.data,
     boxplot(SalePrice ~ YrSinceLastMod.1, xlab = "Age"))
```

Quite expectedly, recently renovated houses fetch a better price. We will 
confirm our observations about the box plots by ANOVA test.
```{r}
oneway.test(SalePrice ~ Age.1, data = age.data)
oneway.test(SalePrice ~ YrSinceLastMod.1, data = age.data)
rm(age.data)
```

The group means are indeed different.

## Roof style and material
These attributes are nominal data. We first check their availability.
```{r}
data_availability("RoofStyle")
data_availability("RoofStyle")
```

Several roof styles have a single observation. Therefore, RoofStyle might not
be a great choice of an attribute to predict sale price. We now examine the 
group means, ANOVA and box plot of RoofStyle.
```{r}
check_group_means("RoofStyle")
```

The group means of RoofStyle are statistically distinct. We will not be able
to conduct an ANOVA for RoofMatl owing to lack of data. We can compute the
group means, nevertheless.
```{r}
with(training.data, tapply(SalePrice, RoofMatl, length))
with(training.data, tapply(SalePrice, RoofMatl, mean))
```

We may want to combine Membran, WdShake and WdShngl into a single category, 
say 'HighEnd' and the remaining into 'Normal'. Let us see if that makes
a difference.
```{r}
roof.mat.data <- training.data[, c("RoofMatl", "SalePrice")]
roof.mat.data$RoofMatl.1 <- 
    ifelse(roof.mat.data$RoofMatl %in% c("Membran", "WdShake", "WdShngl"), 
           "HighEnd", 
           "Normal")
with(roof.mat.data,
     tapply(SalePrice, RoofMatl.1, mean))
oneway.test(SalePrice ~ RoofMatl.1, data = roof.mat.data)
rm(roof.mat.data)
```

Thus, collapsing levels of roof material into two helps determine the mean sale
price.
